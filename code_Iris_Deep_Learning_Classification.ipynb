{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokshpapneja/1/blob/main/code_Iris_Deep_Learning_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPz5Crvv80Kw"
      },
      "source": [
        "# Deep Learning Example - Iris Problem\n",
        "\n",
        "This examples demonstrates the core deep learning model building concepts using the Keras library. The Iris flower dataset is used to build the model and perform classification tasks"
      ],
      "id": "mPz5Crvv80Kw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_ZUIpay80K4"
      },
      "source": [
        "### 5.1 Setup"
      ],
      "id": "O_ZUIpay80K4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L_X09P080K5",
        "outputId": "f054c745-f5a9-4b2a-862c-67bb79831a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=2ead99b18910f11ccd0c804737facfdfef0f467d0ce4cb5a790970d0b7e42359\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "#Install related libraries for the course.\n",
        "#This is a common requirement for all other examples too\n",
        "\n",
        "\n",
        "\n",
        "!pip install pandas\n",
        "!pip install tensorflow\n",
        "!pip install sklearn\n",
        "!pip install matplotlib"
      ],
      "id": "_L_X09P080K5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLuaCnyH80K8"
      },
      "source": [
        "### 4.2. Prepare Input Data for Deep Learning\n",
        "\n",
        "Perform the following steps for preparing data\n",
        "\n",
        "1. Load data into a pandas dataframe\n",
        "2. Convert the dataframe to a numpy array\n",
        "3. Scale the feature dataset\n",
        "4. Use one-hot-encoding for the target variable\n",
        "5. Split into training and test datasets\n"
      ],
      "id": "SLuaCnyH80K8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEzY2LDf80K8",
        "outputId": "948684f6-18e7-468c-ebad-d81d9275fefb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded Data :\n",
            "------------------------------------\n",
            "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "\n",
            "Features before scaling :\n",
            "------------------------------------\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "\n",
            "Target before scaling :\n",
            "------------------------------------\n",
            "[0. 0. 0. 0. 0.]\n",
            "\n",
            "Features after scaling :\n",
            "------------------------------------\n",
            "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
            " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
            " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
            " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
            " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n",
            "\n",
            "Target after one-hot-encoding :\n",
            "------------------------------------\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "\n",
            "Train Test Dimensions:\n",
            "------------------------------------\n",
            "(135, 4) (135, 3) (15, 4) (15, 3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Load Data and review content\n",
        "iris_data = pd.read_csv(\"https://raw.githubusercontent.com/ibtissammakdoun/Introduction-au-deep-learning/main/iris.csv\")\n",
        "# Reads csv file from the pandas framework\n",
        "\n",
        "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
        "print(iris_data.head()) #Prints the column heads\n",
        "\n",
        "#Use a Label encoder to convert String to numeric values\n",
        "#for the target variable\n",
        "\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()  # This is done to define the target: Type of flower into a numeric representation\n",
        "iris_data['Species'] = label_encoder.fit_transform(\n",
        "                                iris_data['Species'])\n",
        "\n",
        "#Convert input to numpy array\n",
        "np_iris = iris_data.to_numpy() # Numpy array is preferred input format for keras\n",
        "\n",
        "#Separate feature and target variables\n",
        "X_data = np_iris[:,0:4] #Takes all data for the first 4 columns: 0,1,2,3 --> Sepal lenth,width and Petal length,width\n",
        "Y_data=np_iris[:,4]#Takes all data and their last column indicating their species that we have to predict\n",
        "\n",
        "#Prints data onto console --> For first 5 values\n",
        "print(\"\\nFeatures before scaling :\\n------------------------------------\")\n",
        "print(X_data[:5,:])\n",
        "print(\"\\nTarget before scaling :\\n------------------------------------\")\n",
        "print(Y_data[:5])\n",
        "\n",
        "#Create a scaler model that is fit on the input data.\n",
        "scaler = StandardScaler().fit(X_data) # Standardizes the input data\n",
        "\n",
        "#Scale the numeric feature variables\n",
        "X_data = scaler.transform(X_data)\n",
        "\n",
        "#Convert target variable as a one-hot-encoding array\n",
        "Y_data = tf.keras.utils.to_categorical(Y_data,3)#Setosa--> 0--> 100 ; 1--> 010 ; 2--> 001 as model target is a multiclass we use one-hot encoding\n",
        "\n",
        "print(\"\\nFeatures after scaling :\\n------------------------------------\")\n",
        "print(X_data[:5,:])\n",
        "print(\"\\nTarget after one-hot-encoding :\\n------------------------------------\")\n",
        "print(Y_data[:5,:])\n",
        "\n",
        "#Split training and test data\n",
        "X_train,X_test,Y_train,Y_test = train_test_split( X_data, Y_data, test_size=0.10)#Test data is 10% and training data is 90% of the whole dataset\n",
        "\n",
        "print(\"\\nTrain Test Dimensions:\\n------------------------------------\")\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ],
      "id": "WEzY2LDf80K8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsRhY2aI80K_"
      },
      "source": [
        "### 4.3. Creating a Model\n",
        "\n",
        "Creating a model in Keras requires defining the following\n",
        "\n",
        "1. Number of hidden layers\n",
        "2. Number of nodes in each layer\n",
        "3. Activation functions\n",
        "4. Loss Function & Accuracy measurements"
      ],
      "id": "OsRhY2aI80K_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PinYm6ui80LA",
        "outputId": "1d932054-e262-4b71-9c3f-5125a836ad54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden-Layer-1 (Dense)      (None, 128)               640       \n",
            "                                                                 \n",
            " Hidden-Layer-2 (Dense)      (None, 128)               16512     \n",
            "                                                                 \n",
            " Output-Layer (Dense)        (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,539\n",
            "Trainable params: 17,539\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "#Number of classes in the target variable\n",
        "NB_CLASSES=3 # Represents the no. of target classes\n",
        "\n",
        "#Create a sequencial model in Keras\n",
        "model = tf.keras.models.Sequential() # A sequential model in keras will have a sequence of layers and hidden layers\n",
        "\n",
        "#Add the first hidden layer\n",
        "model.add(keras.layers.Dense(128,                    #Number of nodes\n",
        "                             input_shape=(4,),       #Number of input variables--> Sepal and Petal Height and width\n",
        "                              name='Hidden-Layer-1', #Logical name\n",
        "                              activation='relu'))    #activation function--> Relu for hidden layer 1\n",
        "\n",
        "#Add a second hidden layer\n",
        "model.add(keras.layers.Dense(128,\n",
        "                              name='Hidden-Layer-2',\n",
        "                              activation='relu'))\n",
        "\n",
        "#Add an output layer with softmax activation\n",
        "model.add(keras.layers.Dense(NB_CLASSES,# Output nodes == No. of classes\n",
        "                             name='Output-Layer',\n",
        "                             activation='softmax')) # Softmax activation function will just selec max probability among the 3 that coe at the node:- (0.7,0.2,0.9)-->0.9\n",
        "\n",
        "#Compile the model with loss & metrics\n",
        "model.compile(loss='categorical_crossentropy', #Need categorical error function\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Print the model meta-data\n",
        "model.summary()\n"
      ],
      "id": "PinYm6ui80LA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUYr_alD80LB"
      },
      "source": [
        "### 4.4. Training and evaluating the Model\n",
        "\n",
        "Training the model involves defining various training models and then perform\n",
        "forward and back propagation."
      ],
      "id": "cUYr_alD80LB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z6GvV_OT80LC",
        "outputId": "617030da-fb7b-45c0-eb73-b55766f49646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Progress:\n",
            "------------------------------------\n",
            "Epoch 1/20\n",
            "7/7 [==============================] - 1s 28ms/step - loss: 0.9488 - accuracy: 0.6389 - val_loss: 0.7745 - val_accuracy: 0.7037\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6131 - accuracy: 0.8519 - val_loss: 0.6119 - val_accuracy: 0.7037\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.8704 - val_loss: 0.5261 - val_accuracy: 0.7407\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8704 - val_loss: 0.4744 - val_accuracy: 0.7778\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8796 - val_loss: 0.4373 - val_accuracy: 0.7778\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2960 - accuracy: 0.8519 - val_loss: 0.4086 - val_accuracy: 0.8148\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2616 - accuracy: 0.8796 - val_loss: 0.3812 - val_accuracy: 0.8148\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.8889 - val_loss: 0.3558 - val_accuracy: 0.8148\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2199 - accuracy: 0.8889 - val_loss: 0.3271 - val_accuracy: 0.8148\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2042 - accuracy: 0.9167 - val_loss: 0.3007 - val_accuracy: 0.8889\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1844 - accuracy: 0.9444 - val_loss: 0.2938 - val_accuracy: 0.8148\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1727 - accuracy: 0.9352 - val_loss: 0.2885 - val_accuracy: 0.8148\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1623 - accuracy: 0.9352 - val_loss: 0.2440 - val_accuracy: 0.9259\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1503 - accuracy: 0.9444 - val_loss: 0.2322 - val_accuracy: 0.9259\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1407 - accuracy: 0.9444 - val_loss: 0.2424 - val_accuracy: 0.8889\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1276 - accuracy: 0.9630 - val_loss: 0.1951 - val_accuracy: 0.9630\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9537 - val_loss: 0.2099 - val_accuracy: 0.9630\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.9444 - val_loss: 0.1736 - val_accuracy: 0.9630\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1169 - accuracy: 0.9537 - val_loss: 0.1889 - val_accuracy: 0.9630\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1073 - accuracy: 0.9444 - val_loss: 0.1693 - val_accuracy: 0.9630\n",
            "\n",
            "Accuracy during Training :\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation against Test Dataset :\n",
            "------------------------------------\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1981 - accuracy: 0.9333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19805912673473358, 0.9333333373069763]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Make it verbose so we can see the progress\n",
        "VERBOSE=1# Print progress during training\n",
        "\n",
        "#Setup Hyper Parameters for training\n",
        "\n",
        "#Set Batch size\n",
        "BATCH_SIZE=16 # Batch size given for faster computations\n",
        "#Set number of epochs\n",
        "EPOCHS=20\n",
        "#Set validation split. 20% of the training data will be used for validation\n",
        "#after each epoch\n",
        "VALIDATION_SPLIT=0.2\n",
        "\n",
        "print(\"\\nTraining Progress:\\n------------------------------------\")\n",
        "\n",
        "#Fit the model. This will perform the entire training cycle, including\n",
        "#forward propagation, loss computation, backward propagation and gradient descent.\n",
        "#Execute for the specified batch sizes and epoch\n",
        "#Perform validation after each epoch\n",
        "history=model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=VERBOSE,\n",
        "          validation_split=VALIDATION_SPLIT)#Trains the model\n",
        "\n",
        "print(\"\\nAccuracy during Training :\\n------------------------------------\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Plot accuracy of the model after each epoch.\n",
        "pd.DataFrame(history.history)[\"accuracy\"].plot(figsize=(8, 5))\n",
        "plt.title(\"Accuracy improvements with Epoch\")\n",
        "plt.show()\n",
        "\n",
        "#Evaluate the model against the test dataset and print results\n",
        "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "id": "Z6GvV_OT80LC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFSLJc0i80LD"
      },
      "source": [
        "### 4.5. Saving and Loading Models\n",
        "\n",
        "The training and inference environments are usually separate. Models need to be saved after they are validated. They are then loaded into the inference environments for actual prediction"
      ],
      "id": "kFSLJc0i80LD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4yIAoGK80LD",
        "outputId": "2d4915f4-b17a-4545-8075-9eca307d8526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Hidden-Layer-1_input with unsupported characters which will be renamed to hidden_layer_1_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden-Layer-1 (Dense)      (None, 2)                 10        \n",
            "                                                                 \n",
            " Hidden-Layer-2 (Dense)      (None, 2)                 6         \n",
            "                                                                 \n",
            " Output-Layer (Dense)        (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25\n",
            "Trainable params: 25\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Saving a model\n",
        "\n",
        "model.save(\"iris_save\")\n",
        "\n",
        "#Loading a Model\n",
        "loaded_model = keras.models.load_model(\"iris_save\")\n",
        "\n",
        "#Print Model Summary\n",
        "loaded_model.summary()"
      ],
      "id": "c4yIAoGK80LD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNXds6Bx80LE"
      },
      "source": [
        "### 4.6. Predictions with Deep Learning Models"
      ],
      "id": "zNXds6Bx80LE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtXr93HE80LE",
        "outputId": "7fed6738-113a-4b8f-863b-801b1b4471ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Prediction Output (Probabilities) : [[0.28652048 0.31853855 0.39494097]]\n",
            "Prediction is  ['virginica']\n"
          ]
        }
      ],
      "source": [
        "#Raw prediction data\n",
        "prediction_input = [[6.6, 3. , 4.4, 1.4]]\n",
        "\n",
        "#Scale prediction data with the same scaling model\n",
        "scaled_input = scaler.transform(prediction_input)\n",
        "\n",
        "#Get raw prediction probabilities\n",
        "raw_prediction = model.predict(scaled_input)\n",
        "print(\"Raw Prediction Output (Probabilities) :\" , raw_prediction)\n",
        "\n",
        "#Find prediction\n",
        "prediction = np.argmax(raw_prediction)\n",
        "print(\"Prediction is \", label_encoder.inverse_transform([prediction]))\n"
      ],
      "id": "CtXr93HE80LE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8NYH5qq80LF",
        "outputId": "ec09ea82-01c3-4715-d641-eaf439c01acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[ 0.8359249 ,  0.8190445 ],\n",
            "       [-0.5539482 , -0.9854561 ],\n",
            "       [-0.60933626, -0.40825883],\n",
            "       [ 0.0203304 , -0.5808915 ]], dtype=float32), array([-0.04449978, -0.03751288], dtype=float32)]\n",
            "[array([[ 0.07239337,  0.83858216],\n",
            "       [ 0.38906744, -0.97707057]], dtype=float32), array([-0.00182586, -0.04882694], dtype=float32)]\n",
            "[array([[-0.84117925, -0.33386418,  0.6198642 ],\n",
            "       [ 0.5622749 ,  0.80120355,  0.4471838 ]], dtype=float32), array([ 0.02371891,  0.00255361, -0.02139328], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "for layer in loaded_model.layers: print(layer.get_weights())\n"
      ],
      "id": "X8NYH5qq80LF"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Number of classes in the target variable\n",
        "NB_CLASSES=3 # Represents the no. of target classes\n",
        "\n",
        "#Create a sequencial model in Keras\n",
        "model1 = tf.keras.models.Sequential() # A sequential model in keras will have a sequence of layers and hidden layers\n",
        "\n",
        "#Add the first hidden layer\n",
        "model1.add(keras.layers.Dense(2,                    #Number of nodes\n",
        "                             input_shape=(4,),       #Number of input variables--> Sepal and Petal Height and width\n",
        "                              name='Hidden-Layer-1', #Logical name\n",
        "                              activation='relu'))    #activation function--> Relu for hidden layer 1\n",
        "\n",
        "#Add a second hidden layer\n",
        "model1.add(keras.layers.Dense(2,\n",
        "                              name='Hidden-Layer-2',\n",
        "                              activation='relu'))\n",
        "\n",
        "#Add an output layer with softmax activation\n",
        "model1.add(keras.layers.Dense(NB_CLASSES,# Output nodes == No. of classes\n",
        "                             name='Output-Layer',\n",
        "                             activation='softmax')) # Softmax activation function will just selec max probability among the 3 that coe at the node:- (0.7,0.2,0.9)-->0.9\n",
        "\n",
        "#Compile the model with loss & metrics\n",
        "model1.compile(loss='categorical_crossentropy', #Need categorical error function\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Print the model meta-data\n",
        "model1.summary()\n",
        "print(model.layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9mKZWtUGAal",
        "outputId": "f52c1705-63e2-404a-e4d1-c4a6a5a2daeb"
      },
      "id": "t9mKZWtUGAal",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Hidden-Layer-1 (Dense)      (None, 2)                 10        \n",
            "                                                                 \n",
            " Hidden-Layer-2 (Dense)      (None, 2)                 6         \n",
            "                                                                 \n",
            " Output-Layer (Dense)        (None, 3)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25\n",
            "Trainable params: 25\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[<keras.layers.core.dense.Dense object at 0x7f0be84c0710>, <keras.layers.core.dense.Dense object at 0x7f0be84c0d10>, <keras.layers.core.dense.Dense object at 0x7f0be84a3b90>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting new weights and biases\n",
        "i=0\n",
        "for layer in loaded_model.layers:\n",
        "  a = layer.get_weights()\n",
        "  model1.layers[i].set_weights(a)\n",
        "  i+=1\n",
        "  print(layer.get_weights())\n",
        "\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "\n",
        "for layer1 in model1.layers:\n",
        "  print(layer1.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnYfomzZGpia",
        "outputId": "c63847c1-07ef-4d60-97ba-638e7abc626d"
      },
      "id": "QnYfomzZGpia",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[ 0.8359249 ,  0.8190445 ],\n",
            "       [-0.5539482 , -0.9854561 ],\n",
            "       [-0.60933626, -0.40825883],\n",
            "       [ 0.0203304 , -0.5808915 ]], dtype=float32), array([-0.04449978, -0.03751288], dtype=float32)]\n",
            "[array([[ 0.07239337,  0.83858216],\n",
            "       [ 0.38906744, -0.97707057]], dtype=float32), array([-0.00182586, -0.04882694], dtype=float32)]\n",
            "[array([[-0.84117925, -0.33386418,  0.6198642 ],\n",
            "       [ 0.5622749 ,  0.80120355,  0.4471838 ]], dtype=float32), array([ 0.02371891,  0.00255361, -0.02139328], dtype=float32)]\n",
            "-------------------------------------------------------------------------------\n",
            "[array([[ 0.8359249 ,  0.8190445 ],\n",
            "       [-0.5539482 , -0.9854561 ],\n",
            "       [-0.60933626, -0.40825883],\n",
            "       [ 0.0203304 , -0.5808915 ]], dtype=float32), array([-0.04449978, -0.03751288], dtype=float32)]\n",
            "[array([[ 0.07239337,  0.83858216],\n",
            "       [ 0.38906744, -0.97707057]], dtype=float32), array([-0.00182586, -0.04882694], dtype=float32)]\n",
            "[array([[-0.84117925, -0.33386418,  0.6198642 ],\n",
            "       [ 0.5622749 ,  0.80120355,  0.4471838 ]], dtype=float32), array([ 0.02371891,  0.00255361, -0.02139328], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Raw prediction data\n",
        "prediction_input = [[6.6, 3. , 4.4, 1.4]]\n",
        "\n",
        "#Scale prediction data with the same scaling model\n",
        "scaled_input = scaler.transform(prediction_input)\n",
        "raw_prediction = model1.predict(scaled_input)\n",
        "print(\"Raw Prediction Output (Probabilities) :\" , raw_prediction)\n",
        "\n",
        "#Find prediction\n",
        "prediction = np.argmax(raw_prediction)\n",
        "print(\"Prediction is \", label_encoder.inverse_transform([prediction]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wcK_VytKHJ5",
        "outputId": "a93d2a44-3d81-499c-c78d-14fa306913ce"
      },
      "id": "0wcK_VytKHJ5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Prediction Output (Probabilities) : [[0.28652048 0.31853855 0.39494097]]\n",
            "Prediction is  ['virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LM4eGRXGNQY3"
      },
      "id": "LM4eGRXGNQY3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}